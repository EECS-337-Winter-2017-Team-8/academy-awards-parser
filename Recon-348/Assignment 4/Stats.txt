Simple Naive Bayes:
Accuracy:	0.8822382671480143
Precision:	0.8144148516729712
Recall:		0.8263405209898016
F1 Measure:	0.8191465688893885

Best Bayes:
Accuracy:	0.8840433212996389
Precision:	0.815521384242666
Recall:		0.8412832371465464
F1 Measure:	0.8260712539681965


Lowercasing and Punctuation Stripping:
Accuracy:	0.8928519855595669
Precision:	0.8303196563153807
Recall:		0.8453869871136058
F1 Measure:	0.8364540663583784

NLTK Tokenizer, Stand-Alone
Accuracy:	0.6808664259927799
Precision:	0.6071535263148655
Recall:		0.6564399030226368
F1 Measure:	0.6050628241483287

NLTK Tokenizer with Lowercasing:
Accuracy:	0.6922743682310469
Precision:	0.6140450529104242
Recall:		0.6645115226500119
F1 Measure:	0.614779060365429

NLTK Tokenizer, Stand-Alone (Smaller Subset of Test Data):
Accuracy:	0.6520833333333333
Precision:	0.6544115083877513
Recall:		0.6520833333333333
F1 Measure:	0.6502539709867798

NLTK Tokenizer with Stripping - POS Tokens (Smaller Subset of Test Data)
Accuracy:	0.8270833333333334
Precision:	0.8347275909408015
Recall:		0.8270833333333334
F1 Measure:	0.8260532876623522

NLTK Tokenizer with Stripping - Non-POS Tokens (Smaller Subset of Test Data)
Accuracy:	0.84375
Precision:	0.8495719481029042
Recall:		0.84375
F1 Measure:	0.8431150529522526

"", Nouns added back in (Smaller Subset of Test Data)
Accuracy:	0.8666666666666668
Precision:	0.8691476993818423
Recall:		0.8666666666666668
F1 Measure:	0.8664053182700682

"", Pronouns added back in (Smaller Subset of Test Data)
Accuracy:	0.8697916666666667
Precision:	0.8725611684355499
Recall:		0.8697916666666667
F1 Measure:	0.8694977908012355

"", With Stemming (Smaller Subset of Test Data)
Accuracy:	0.86875
Precision:	0.8709286395268748
Recall:		0.86875
F1 Measure:	0.8685059158617274
